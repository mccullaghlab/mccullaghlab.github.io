{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618ff02f",
   "metadata": {},
   "source": [
    "# Enzyme Kinetics: The Michaelis-Menten Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b73323",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Enzymes are biomolecules (most commonly proteins) that catalyze a wide variety of biochemical reactions.  These important molecules facilitate almost every important process in cellular biology.  The kinetics of these biological catalysts is of interest for understanding the basic science of how our body works as well as the design of novel industrial chemical syntheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eadd79",
   "metadata": {},
   "source": [
    "## Learning Goals:\n",
    "\n",
    "After working through these notes, you will be able to:\n",
    "\n",
    "1. Delineate the steps and approximations in the Michaelis-Menten mechanism for enzyme kinetics.\n",
    "2. Express the rate of change of reactant (/substrate) change in terms of Michaelis-Menten parameters.\n",
    "3. Use a Lineweaver-Burk plot (/equation) to fit Michaelis-Menten parameters.\n",
    "4. Describe how to setup an experiment to measure Michaelis-Menten parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f71991",
   "metadata": {},
   "source": [
    "## Coding Concepts:\n",
    "\n",
    "The following coding concepts are used in this notebook:\n",
    "\n",
    "1. [Variables](../../coding_concepts/variables.ipynb)\n",
    "2. [Functions](../../coding_concepts/functions.ipynb)\n",
    "3. [Plotting with matplotlib](../../coding_concepts/plotting_with_matplotlib.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89bd414",
   "metadata": {},
   "source": [
    "## Enzymes are Biological Catalysts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c6b75",
   "metadata": {},
   "source": [
    "Enzyzmes are proteins that catalyze chemical reactions.  The type of reactions span the gamut of biochemical processes including almost every step of glycolysis to the hydrolysis of ATP in motor proteins.  Enzymes are known to speed-up chemical reactions by many orders of magnitude (as much as $10^5-10^{12}$).  \n",
    "\n",
    "Without enzymes, life as we know it would not exist.  Processes would occur at rates far to slow to sustain life.  \n",
    "\n",
    "So how do enzymes achieve such amazing speed-ups?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da2be8",
   "metadata": {},
   "source": [
    "## Proposed Mechanism for Enzyme Catalysis: The Michaelis-Menten Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb8d674",
   "metadata": {},
   "source": [
    "The most ubiquitous, and one of the simplest, mechanisms for enzyme catalysis was proposed my Leonor Michaelis and Maude Menten in 1913.  It is still the go-to mechanism for fitting enzyme kinetics.  The derivation is as follows.\n",
    "\n",
    "Consider a generic process of converting a substrate to a product with chemical reaction\n",
    "\\begin{equation}\n",
    "S \\underset{E}{\\longrightarrow} P,\n",
    "\\end{equation}\n",
    "where $S$ is the substrate (aka reactant), $E$ is the enzyme, and $P$ is the product.  It was found, experimentally, that many enzyme catalyzed reactions of this form followed the rate law \n",
    "\\begin{equation}\n",
    "-\\frac{d[S]}{dt} = \\frac{k[S]}{K+[S]}.\n",
    "\\end{equation}\n",
    "\n",
    "Michealis and Menten proposed a two-step mechanism whereby the enzyme and substrate form an intermediate (called the enzyme-substrate complex) in a reversible reaction, followed by another reversible reaction in which the substrate is converted into product.  This can be written as\n",
    "\\begin{align}\n",
    "E + S &\\overset{k_1}{\\underset{k_{-1}}{\\overset{\\Longrightarrow}{\\Longleftarrow}}} ES \\\\\n",
    "ES &\\overset{k_2}{\\underset{k_{-2}}{\\overset{\\Longrightarrow}{\\Longleftarrow}}} E + P\n",
    "\\end{align}\n",
    "Note that it is common to assume the second step is irreversible but it is not necessary to do so.  \n",
    "\n",
    "The above mechansim leads to the following three differential equations\n",
    "\\begin{align}\n",
    "-\\frac{d[S]}{dt}  &= k_1[E][S] - k_{-1}[ES] \\\\\n",
    "-\\frac{d[ES]}{dt}  &= (k_2+k_{-1})[ES] - k_1[E][S] - k_{-2}[E][P] \\\\\n",
    "\\frac{d[P]}{dt} &= k_2[ES] - k_{-2}[E][P]\n",
    "\\end{align}\n",
    "Because enzyme is not created or destroyed during the reaction, the overall concentration of enzyme containing species is fixed as the initial concentration of enzyme.  That is\n",
    "\\begin{equation}\n",
    "[E]_0 = [E] + [ES]\n",
    "\\end{equation}\n",
    "Substituting this into the differential equations above gives\n",
    "\\begin{align}\n",
    "-\\frac{d[S]}{dt}  &= k_1[E]_0[S] - (k_{-1}+k_1[S])[ES] \\\\\n",
    "-\\frac{d[ES]}{dt}  &= (k_1[S] + k_{-2}[P] + k_2+k_{-1})[ES] - k_1[E]_0[S] - k_{-2}[E]_0[P] \\\\\n",
    "\\frac{d[P]}{dt} &= (k_2+k_{-2}[P])[ES] - k_{-2}[E]_0[P]\n",
    "\\end{align}\n",
    "These equations cannot be solved analytically for $[S]$, $[E]$, and/or $[P]$ without further approximation.  \n",
    "\n",
    "*The first approximation employed is the steady-state approximation for $[ES]$.*  This approximation is typically valid after an intial phase of building up the $ES$ concentration when enzyme is mixed with excess substrate. After the initial lag phase, but before much substrate has been consumed and/or product has been formed, the steady-state approximation will be achieved yielding\n",
    "\\begin{eqnarray}\n",
    "-\\frac{d[ES]}{dt}  &\\overset{s.s.}{=}& 0 = (k_1[S] + k_{-2}[P] + k_2+k_{-1})[ES] - k_1[E]_0[S] - k_{-2}[E]_0[P] \\\\\n",
    "\\Rightarrow [ES] &\\overset{s.s.}{=}& \\frac{(k_1[S]+k_{-2}[P])[E]_0}{k_1[S] + k_{-2}[P] + k_{-1} + k_2}.\n",
    "\\end{eqnarray}\n",
    "\n",
    "Substituting the steady-state approximation for the concentration of the enzyme-substrate complex into the differential equation for substrate concentration yields\n",
    "\\begin{align}\n",
    "-\\frac{d[S]}{dt}  &= k_1[E]_0[S] - (k_{-1}+k_1[S])\\frac{(k_1[S]+k_{-2}[P])[E]_0}{k_1[S] + k_{-2}[P] + k_{-1} + k_2} \\\\\n",
    "&= k_1[E]_0[S]\\frac{(k_1[S] + k_{-2}[P] + k_{-1} + k_2)}{k_1[S] + k_{-2}[P] + k_{-1} + k_2}  - (k_{-1}+k_1[S])\\frac{(k_1[S]+k_{-2}[P])[E]_0}{k_1[S] + k_{-2}[P] + k_{-1} + k_2} \\\\\n",
    "&= \\frac{k_1[E]_0[S]k_1[S] + k_1[E]_0[S]k_{-2}[P] + k_1[E]_0[S]k_{-1} + k_1[E]_0[S]k_2 - k_{-1}k_1[S][E]_0 - k_{-1}k_{-2}[P][E]_0 -k_1[S]k_1[S][E]_0 - k_1[S] k_{-2}[P][E]_0}{k_1[S] + k_{-2}[P] + k_{-1} + k_2}\\\\\n",
    "&= \\frac{k_1k_2[E]_0[S] - k_{-1}k_{-2}[P][E]_0}{k_1[S] + k_{-2}[P] + k_{-1} + k_2}\n",
    "\\end{align}\n",
    "\n",
    "If we now dictate that we will only measure the intitial rate of the reaction (post lag phase) and that there is only reactant/substrate present initially, then we can make the following approximations\n",
    "\\begin{align}\n",
    "&[S] \\approx [S]_0 \\\\\n",
    "&[P] \\approx [P]_0 = 0\n",
    "\\end{align}\n",
    "Plugging in these approximations to the Michaelis-Menten rate equation yields\n",
    "\\begin{align}\n",
    "v_0 = -\\frac{d[S]}{dt}|_0 &= \\frac{k_1k_2[E]_0[S]_0}{k_1[S]_0 + k_{-1} + k_2} \\\\\n",
    "&= \\frac{k_2[E]_0[S]_0}{K_m + [S]_0}\n",
    "\\end{align}\n",
    "where the last equality holds true for $K_m = \\frac{k_{-1} + k_2}{k_1}$.  This quantity is called the  *Michaelis-Menten constant* or the *Michaelis-Menten binding constant*.   Note that this quantity is ***not*** the equilibrium constant for the first step in the Michaelis-Menten mechanism.\n",
    "\n",
    "We see an example plot of initial rate vs. initial substrate concentration below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ad6331",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig = plt.figure(figsize=(8,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(111)\n",
    "ax.grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax.set_ylabel(\"$v_0$ ($\\mu$M/s)\",size=fontsize)\n",
    "ax.set_xlabel(\"$[S]_0$ ($\\mu$M)\",size=fontsize)\n",
    "plt.tick_params(axis='both',labelsize=fontsize)\n",
    "def mm(S0,vmax,Km):  \n",
    "    return vmax*S0/(Km + S0)\n",
    "vmax = 0.001\n",
    "Km = 10\n",
    "S0 = np.arange(0,100,0.1)\n",
    "ax.plot(S0,mm(S0,vmax,Km),lw=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d40de1",
   "metadata": {},
   "source": [
    "We notice from the plot above that the initial rate saturates/plateaus as the initial substrate concentration is increased.  Indeed, it is readily shown that the maximum initial rate, denoted $v_{max}$, is \n",
    "\\begin{eqnarray}\n",
    "v_{max} = \\lim_{[S]_0\\rightarrow\\infty} v_0 = k_2[E]_0\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18371c34",
   "metadata": {},
   "source": [
    "## Experiments to Measure Michaelis-Menten Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312249a",
   "metadata": {},
   "source": [
    "For an enzyme catalyzed reaction that follows the Michaelis-Menten mechanism, the parameters $K_m$ and $v_{max}$ allow us to determine the rate of reaction at aribtraty substrate concentration.  These parameters can be compared amongst enzymes or across experimental conditions to assess the efficiency of an enzyme.  Indeed, these parameters are still estimated for a number of enzymes today.  \n",
    "\n",
    "To consider how to design an experiment to estimate these parameters, we start writing out the chemical reaction \n",
    "\\begin{equation}\n",
    "S \\underset{E}{\\longrightarrow} P,\n",
    "\\end{equation}\n",
    "and the associated Michaelis-Menten rate equation\n",
    "\\begin{align}\n",
    "v_0 = \\frac{v_{max}[S]_0}{K_m + [S]_0}\n",
    "\\end{align}\n",
    "\n",
    "We need to measure $v_0$ as a function of $[S]_0$ to determine $v_{max}$ and $K_m$.  This can be done in a number of ways but there are two critical components:\n",
    "\n",
    "1. Some way of measuring the initial rate of reaction.  The specifics of this measurement will depend on the reaction and reaction conditions.  An example might be absorbance spectroscopy - if the product absorbs light at a different frequency than the reactant, then measuring absorbance as a function of time will provide the appropriate information.\n",
    "2. Performing multiple trials altering the initial concentration of substrate.\n",
    "\n",
    "After these experiments, one will have concentration (or something proportional to concentration) as a function of initial concentration of substrate.  From here, it is a question of fitting the resulting data to the above equation for $v_0$ to determine v_{max}$ and $K_m$.  This can be done using a non-linear fit or using a Lineweaver-Burke plot.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b8c2cf",
   "metadata": {},
   "source": [
    "## Fitting Michaelis-Menten Parameters using a Lineweaver-Burk Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7832b4",
   "metadata": {},
   "source": [
    "A Lineweaver-Burk plot is a plot of $\\frac{1}{v_0}$ vs. $\\frac{1}{[S]_0}$ and can be considered a linearized form of the Michaelis-Menten equation.  \n",
    "\n",
    "To demonstrate this, we start with the Michaelis-Menten initial rate equation and take the reciprocal of both sides:\n",
    "\\begin{align}\n",
    "v_0 &= \\frac{v_{max}[S]_0}{K_m + [S]_0} \\\\\n",
    "\\Rightarrow \\frac{1}{v_0} &= \\frac{K_m + [S]_0}{v_{max}[S]_0} \\\\\n",
    "&= \\frac{K_m}{v_{max}}\\frac{1}{[S]_0} + \\frac{1}{v_{max}}\n",
    "\\end{align}\n",
    "\n",
    "This last equation is known as the Lineweaver-Burk equation and demonstrates that $\\frac{1}{v_0}$ will be linear with respect to $\\frac{1}{[S]_0}$ for enzyme kinetics that is well modeled by the Michaelis-Menten mechanism.  The slope of the line will be $\\frac{K_m}{v_{max}}$ and the intercept is $\\frac{1}{v_{max}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f5bc2",
   "metadata": {},
   "source": [
    "## The Importance of v/K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11d204",
   "metadata": {},
   "source": [
    "The value of $v_{max}/K_m$ (or, $k_2/K_m$), is a measure of the efficiency of an enzyme.   To see why this value is important, consider the MM rate law\n",
    "\\begin{equation}\n",
    "v_0 = \\frac{v_{max}[S]_0}{K_m + [S]_0}\n",
    "\\end{equation}\n",
    "When $K_m >> [S]_0$, we have that \n",
    "\\begin{equation}\n",
    "v_0 \\approx \\frac{v_{max}}{K_m}[S]_0 = \\frac{k_{2}}{K_m}[E]_0[S]_0\n",
    "\\end{equation}\n",
    "or that the reaction is first order in substrate, first order in enzyme, and second order overall with observed rate constant of $\\frac{k_2}{K_m}$.  \n",
    "\n",
    "$\\frac{k_2}{K_m}$ will have units of M$^{-1}\\cdot$s$^{-1}$ and is related to the number of collisions that lead to reaction. The higher the value of  $\\frac{k_2}{K_m}$ the more efficient the enzyme.  Value near $10^9$ are the maximum indicating that the reaction is diffusion controlled and thus effectively every collision leads to reaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b18914",
   "metadata": {},
   "source": [
    "## Comparing MM Parameters For Different Enzymes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce762a5",
   "metadata": {},
   "source": [
    "Michaelis-Menten Parameter are tabulated for various enzymes.  These can be compared to assess the relative efficiency of these enzymes.\n",
    "\n",
    "| Enzyme  |  Substrate | $K_m$ (M) | $k_{2}$ (s$^{-1}$) | $\\frac{k_2}{K_m}$ (M$^{-1}\\cdot$s$^{-1}$) |\n",
    "| :-----  | :--------- | :-------- | :----------------- | :-------------------------------         |\n",
    "| Acetylcholineterase | Acetylcholine | $9.5\\times10^{-5}$ | $1.4\\times10^4$ | $1.5\\times10^8$ |\n",
    "| Carbonic anhydrase | CO$_2$ | $1.2\\times10^{-2}$ | $1.0\\times10^6$ | $8.3\\times10^7$ |\n",
    "| Carbonic anhydrase | HCO$_3^-$ | $2.6\\times10^{-2}$ | $4.0\\times10^5$ | $1.5\\times10^7$ |\n",
    "| Catalase | H$_2$O$_2$ | $2.5\\times10^{-2}$ | $1.0\\times10^7$ | $4.0\\times10^8$ |\n",
    "\n",
    "In the table above we see various examples of enzymes substrate pairs and their associated Michaelis-Menten parameters.  Carbonic anhydrase, for example, can bind either CO$_2$ or HCO$_3^-$ and has different MM parameters for those substrates.  As a summary, the enzymative efficiency ($\\frac{k_2}{K_m}$) of Carbonic anhydrase is larger for CO$_2$ as a substrate as compared to HCO$_3^-$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c0e19d",
   "metadata": {},
   "source": [
    "## Example: Fitting Michaelis-Menten Parameters\n",
    "\n",
    "Determine the Michaelis-Menten Paramters from the following data\n",
    "\n",
    "| $[S]_0$ (mM) | $v_0$ ($\\mu$M/s) |\n",
    "| :----------- | :--------------- |\n",
    "|   1          | 2.5              |\n",
    "|   2          | 4.0              |\n",
    "| 5            | 6.3              |\n",
    "| 10           | 7.6              |\n",
    "| 20           | 9.0              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a892058",
   "metadata": {},
   "source": [
    "### Solution: Non-linear Fitting\n",
    "\n",
    "We will simply solve this by performing a non-linear fit to the Michaelis-Menten parameters.  We start by entering the data into arrays and plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad3286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the data into numpy arrays\n",
    "import numpy as np\n",
    "s0 = np.array([1,2,5,10,20.0])\n",
    "v0 = np.array([2.5,4.0,6.3,7.6,9.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa285a4",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig = plt.figure(figsize=(8,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(111)\n",
    "ax.grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax.set_ylabel(\"$v_0$ ($\\mu$M/s)\",size=fontsize)\n",
    "ax.set_xlabel(\"$[S]_0$ (mM)\",size=fontsize)\n",
    "plt.tick_params(axis='both',labelsize=fontsize)\n",
    "ax.plot(s0,v0,'o',lw=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff4947ae",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_max =  10.3 +/- 0.2 muM/s\n",
      "Km =  3.2 +/- 0.2 mM\n"
     ]
    }
   ],
   "source": [
    "# perform non-linear fit\n",
    "# import least squares function from scipy library\n",
    "from scipy.optimize import curve_fit\n",
    "# define Michaelis-Menten function\n",
    "def mm(s,vmax,Km):  \n",
    "    return vmax*s/(Km + s)\n",
    "# make an initial guess of parameters\n",
    "x0 = np.array([1.0,1.0])\n",
    "popt, pcov = curve_fit(mm, s0, v0)\n",
    "err = np.sqrt(np.diag(pcov))\n",
    "print(\"v_max = \", np.round(popt[0],1),\"+/-\", np.round(err[0],1), \"muM/s\")\n",
    "print(\"Km = \", np.round(popt[1],1),\"+/-\", np.round(err[1],1), \"mM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee21e8fa",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig = plt.figure(figsize=(8,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(111)\n",
    "ax.grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax.set_ylabel(\"$v_0$ ($\\mu$M/s)\",size=fontsize)\n",
    "ax.set_xlabel(\"$[S]_0$ (mM)\",size=fontsize)\n",
    "plt.tick_params(axis='both',labelsize=fontsize)\n",
    "ax.plot(s0,v0,'o',lw=2)\n",
    "s = np.arange(np.amin(s0),np.amax(s0),0.01)\n",
    "ax.plot(s,mm(s,popt[0],popt[1]),lw=3,label=\"fit\")\n",
    "plt.legend(fontsize=fontsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2987a",
   "metadata": {},
   "source": [
    "### Solution: Lineweaver-Burk Plot\n",
    "\n",
    "In this solution we will plot $1/v_0$ vs $1/[S]_0$ and fit the resulting data to a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33592b93",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig = plt.figure(figsize=(8,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(111)\n",
    "ax.grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax.set_ylabel(\"$1/v_0$ (s/$\\mu$M)\",size=fontsize)\n",
    "ax.set_xlabel(\"$1/[S]_0$ (1/mM)\",size=fontsize)\n",
    "plt.tick_params(axis='both',labelsize=fontsize)\n",
    "ax.plot(1/s0,1/v0,'o',lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9480f",
   "metadata": {},
   "source": [
    "Fit the line to get the MM parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f47dc0f",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope =  0.302 +/- 0.003\n",
      "Intercept =  0.099 +/- 0.001\n",
      "R^2 =  0.9997345039696032\n",
      "v_max =  10.1 +/- 0.1 muM/s\n",
      "Km =  3.1 +/- 0.1 mM\n"
     ]
    }
   ],
   "source": [
    "# perform linear fit\n",
    "# import least squares function from scipy library\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "# define Michaelis-Menten function\n",
    "def mm_lineweaver_burke(s,m,b):  \n",
    "    return m*s + b\n",
    "# perform fit\n",
    "popt_lwb, pcov = curve_fit(mm_lineweaver_burke, 1/s0, 1/v0)\n",
    "err_lwb = np.sqrt(np.diag(pcov))\n",
    "print(\"Slope = \", np.round(popt_lwb[0],3), \"+/-\", np.round(err_lwb[0],3))\n",
    "print(\"Intercept = \", np.round(popt_lwb[1],3), \"+/-\", np.round(err_lwb[1],3))\n",
    "y_pred = mm_lineweaver_burke(1/s0,*popt_lwb)\n",
    "print(\"R^2 = \", r2_score(1/v0, y_pred))\n",
    "vmax_lwb = 1/popt_lwb[1]\n",
    "vmax_lwb_err = vmax_lwb*err_lwb[1]/popt_lwb[1]\n",
    "Km_lwb = popt_lwb[0]/popt_lwb[1]\n",
    "Km_lwb_err = Km_lwb*np.sqrt( (err_lwb[0]/popt_lwb[0])**2 + (err_lwb[1]/popt_lwb[1])**2)\n",
    "print(\"v_max = \", np.round(vmax_lwb,1),\"+/-\", np.round(vmax_lwb_err,1), \"muM/s\")\n",
    "print(\"Km = \", np.round(Km_lwb,1),\"+/-\", np.round(Km_lwb_err,1), \"mM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f33a7",
   "metadata": {},
   "source": [
    "Plot the resulting Lineweaver-Burk plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e346ec72",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig = plt.figure(figsize=(8,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(111)\n",
    "ax.grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax.set_ylabel(\"$1/v_0$ (s/$\\mu$M)\",size=fontsize)\n",
    "ax.set_xlabel(\"$1/[S]_0$ (1/mM)\",size=fontsize)\n",
    "plt.tick_params(axis='both',labelsize=fontsize)\n",
    "ax.plot(1/s0,1/v0,'o',lw=2)\n",
    "s = np.arange(np.amin(1/s0),np.amax(1/s0),0.01)\n",
    "ax.plot(s,mm_lineweaver_burke(s,popt_lwb[0],popt_lwb[1]),lw=3,label=\"fit\")\n",
    "plt.legend(fontsize=fontsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a763df",
   "metadata": {},
   "source": [
    "### Compare Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63380526",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig = plt.figure(figsize=(8,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(111)\n",
    "ax.grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax.set_ylabel(\"$v_0$ ($\\mu$M/s)\",size=fontsize)\n",
    "ax.set_xlabel(\"$[S]_0$ (mM)\",size=fontsize)\n",
    "plt.tick_params(axis='both',labelsize=fontsize)\n",
    "ax.plot(s0,v0,'o',lw=2)\n",
    "s = np.arange(np.amin(s0),np.amax(s0),0.01)\n",
    "ax.plot(s,mm(s,popt[0],popt[1]),lw=3,label=\"non-linear fit\")\n",
    "ax.plot(s,mm(s,vmax_lwb,Km_lwb),'--',lw=3,label=\"linear fit\")\n",
    "plt.legend(fontsize=fontsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ac987",
   "metadata": {},
   "source": [
    "## Example: Fitting with Random Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1d41c",
   "metadata": {},
   "source": [
    "Here we consider fitting MM parameters using either the Lineweaver-Burk linearization or non-linear regression.  Which method is better?  To investigate this, we generate a set of fake data using a known $K_m$ and $v_{max}$ and then fit the data using both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bac7d0",
   "metadata": {},
   "source": [
    "Below is a piece of code that will generate a fake data with random error (a fractional noise around the true value) set for initial concentrations of $1, 2, 5, 10, 20$ mM.  We will use Michaelis-Menten parameters of\n",
    "\\begin{align}\n",
    "V_{max} &= 7.5 \\text{ }\\mu\\text{M}\\cdot\\text{s}^{-1}\\\\\n",
    "K_m &= 4.0 \\text{ mM}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a310da96",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [S]0    Trial 1    Trial 2    Trial 3    Trial 4    Trial 5\n",
      "------  ---------  ---------  ---------  ---------  ---------\n",
      "     1    1.58055    1.48231    1.45284    1.46868    1.42774\n",
      "     2    2.51128    2.48937    2.38814    2.37044    2.61247\n",
      "     5    4.10746    4.26795    4.00625    4.0436     4.08355\n",
      "    10    5.59876    5.3423     5.40568    5.41915    5.69761\n",
      "    20    6.04273    6.00477    6.29373    6.15206    6.04343\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "s0 = np.array([1,2,5,10,20.0])\n",
    "# Generate a data set\n",
    "def mm_from_params(S0,vmax,Km):  \n",
    "    return vmax*S0/(Km + S0)\n",
    "vmax = 7.5\n",
    "Km = 4.0\n",
    "truth = mm_from_params(s0,vmax,Km)\n",
    "n_trials = 5\n",
    "data = np.empty((truth.shape[0],n_trials))\n",
    "s0_total = np.empty((s0.shape[0],n_trials))\n",
    "for i in range(n_trials):\n",
    "    # estimate error based on normal distribution 99.9% data within 7.5%\n",
    "    error = np.random.normal(0,0.03,truth.shape[0])\n",
    "    # estimate error from uniform distribution with maximum value of 5%\n",
    "    #error = 0.1*(np.random.rand(truth.shape[0])-0.5)\n",
    "    # generate data by adding error to truth\n",
    "    data[:,i] = truth*(1+error)\n",
    "    # keep flattened s0 array\n",
    "    s0_total[:,i] = s0\n",
    "combined_data = np.column_stack((s0,data))\n",
    "print(tabulate(combined_data,headers=[\"[S]0\",\"Trial 1\", \"Trial 2\", \"Trial 3\", \"Trial 4\", \"Trial 5\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560cdadc",
   "metadata": {},
   "source": [
    "The data in both standard and linear form look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a741a1b2",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig, ax = plt.subplots(1,2,figsize=(16,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax[0].grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax[0].set_ylabel(\"$v_0$ ($\\mu$M/s)\",size=fontsize)\n",
    "ax[0].set_xlabel(\"$[S]_0$ (mM)\",size=fontsize)\n",
    "ax[0].tick_params(axis='both',labelsize=fontsize)\n",
    "for i in range(n_trials):\n",
    "    ax[0].plot(s0,data[:,i],'o')\n",
    "ax[0].plot(s0,truth,'-',lw=2,label=\"Truth\")\n",
    "ax[1].grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax[1].set_ylabel(\"$1/v_0$ (s/$\\mu$M)\",size=fontsize)\n",
    "ax[1].set_xlabel(\"$1/[S]_0$ (1/mM)\",size=fontsize)\n",
    "ax[1].tick_params(axis='both',labelsize=fontsize)\n",
    "for i in range(n_trials):\n",
    "    ax[1].plot(1/s0,1/data[:,i],'o')\n",
    "ax[1].plot(1/s0,1/truth,'-',lw=2,label=\"Truth\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1231e",
   "metadata": {},
   "source": [
    "Now to perform the fits.  We start with the linear least-squares using the Lineweaver-Burk formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348be75e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_max =  7.5 +/- 0.2 muM/s\n",
      "Km =  4.1 +/- 0.1 mM\n"
     ]
    }
   ],
   "source": [
    "# perform linear fit\n",
    "# import least squares function from scipy library\n",
    "from scipy.optimize import curve_fit\n",
    "# define Michaelis-Menten function\n",
    "def mm_lineweaver_burke(s,m,b):  \n",
    "    return m*s + b\n",
    "# make an initial guess of parameters\n",
    "popt_lwb, pcov = curve_fit(mm_lineweaver_burke, 1/s0_total.flatten(), 1/data.flatten())\n",
    "err_lwb = np.sqrt(np.diag(pcov))\n",
    "vmax_lwb = 1/popt_lwb[1]\n",
    "vmax_lwb_err = vmax_lwb*err_lwb[1]/popt_lwb[1]\n",
    "Km_lwb = popt_lwb[0]/popt_lwb[1]\n",
    "Km_lwb_err = Km_lwb*np.sqrt( (err_lwb[0]/popt_lwb[0])**2 + (err_lwb[1]/popt_lwb[1])**2)\n",
    "print(\"v_max = \", np.round(vmax_lwb,1),\"+/-\", np.round(vmax_lwb_err,1), \"muM/s\")\n",
    "print(\"Km = \", np.round(Km_lwb,1),\"+/-\", np.round(Km_lwb_err,1), \"mM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad4ce8",
   "metadata": {},
   "source": [
    "Now we perform non-linear least squares using the standard Michaelis-Menten rate equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84dcbe53",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_max =  7.4 +/- 0.1 muM/s\n",
      "Km =  3.9 +/- 0.2 mM\n"
     ]
    }
   ],
   "source": [
    "# perform non-linear fit\n",
    "# import least squares function from scipy library\n",
    "from scipy.optimize import curve_fit\n",
    "# define Michaelis-Menten function\n",
    "def mm(s,vmax,Km):  \n",
    "    return vmax*s/(Km + s)\n",
    "# make an initial guess of parameters\n",
    "x0 = np.array([1.0,1.0])\n",
    "popt, pcov = curve_fit(mm, s0_total.flatten(), data.flatten())\n",
    "err = np.sqrt(np.diag(pcov))\n",
    "print(\"v_max = \", np.round(popt[0],1),\"+/-\", np.round(err[0],1), \"muM/s\")\n",
    "print(\"Km = \", np.round(popt[1],1),\"+/-\", np.round(err[1],1), \"mM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92918095",
   "metadata": {},
   "source": [
    "You can see that both methods produce reasonable results.  They can be compared visually by looking at the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d33437b",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig, ax = plt.subplots(1,1,figsize=(8,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax.grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax.set_ylabel(\"$v_0$ ($\\mu$M/s)\",size=fontsize)\n",
    "ax.set_xlabel(\"$[S]_0$ (mM)\",size=fontsize)\n",
    "ax.tick_params(axis='both',labelsize=fontsize)\n",
    "for i in range(n_trials):\n",
    "    ax.plot(s0,data[:,i],'o')\n",
    "s = np.arange(1,20,0.01)\n",
    "ax.plot(s,mm(s,vmax,Km),'-',lw=3,label=\"Truth\")\n",
    "ax.plot(s,mm(s,popt[0],popt[1]),'--',lw=2,label=\"non-linear fit\")\n",
    "ax.plot(s,mm(s,vmax_lwb,Km_lwb),'--',lw=2,label=\"linear fit\")\n",
    "plt.legend(fontsize=fontsize);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0fec6b",
   "metadata": {},
   "source": [
    "## Example: Fitting with Systematic Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76bcc4b",
   "metadata": {},
   "source": [
    "Now we will investigate how the two fitting procedures deal with systematic error.  This error is a fixed value rather than a percentage of each true result.  This is a better mimic of an error for a given instrument.  Below is a piece of code that will generate a fake data with systematic error for initial concentrations of $1, 2, 5, 10, 20$ mM.  We will use Michaelis-Menten parameters of\n",
    "\\begin{align}\n",
    "V_{max} &= 7.5 \\text{ }\\mu\\text{M}\\cdot\\text{s}^{-1}\\\\\n",
    "K_m &= 4.0 \\text{ mM}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b9182f2",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [S]0    Trial 1    Trial 2    Trial 3    Trial 4    Trial 5\n",
      "------  ---------  ---------  ---------  ---------  ---------\n",
      "     1    1.58063    1.57082    1.46432    1.48848    1.14969\n",
      "     2    2.42013    2.50682    2.48827    2.46851    2.48492\n",
      "     5    4.39403    4.11677    4.16641    4.10888    4.14527\n",
      "    10    5.26992    5.27886    5.20479    5.33248    5.32643\n",
      "    20    6.50389    6.19816    6.35539    6.33411    6.29735\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "s0 = np.array([1,2,5,10,20.0])\n",
    "# Generate a data set\n",
    "def mm_from_params(S0,vmax,Km):  \n",
    "    return vmax*S0/(Km + S0)\n",
    "vmax = 7.5\n",
    "Km = 4.0\n",
    "truth = mm_from_params(s0,vmax,Km)\n",
    "n_trials = 5\n",
    "data = np.empty((truth.shape[0],n_trials))\n",
    "s0_total = np.empty((s0.shape[0],n_trials))\n",
    "for i in range(n_trials):\n",
    "    # estimate error based on normal distribution 99.9% data within 7.5%\n",
    "    error = np.random.normal(0,0.1,truth.shape[0])\n",
    "    data[:,i] = truth+error\n",
    "    # keep flattened s0 array\n",
    "    s0_total[:,i] = s0\n",
    "combined_data = np.column_stack((s0,data))\n",
    "print(tabulate(combined_data,headers=[\"[S]0\",\"Trial 1\", \"Trial 2\", \"Trial 3\", \"Trial 4\", \"Trial 5\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fe236f3",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# plot data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# setup plot parameters\n",
    "fontsize=16\n",
    "fig, ax = plt.subplots(1,2,figsize=(16,8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax[0].grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax[0].set_ylabel(\"$v_0$ ($\\mu$M/s)\",size=fontsize)\n",
    "ax[0].set_xlabel(\"$[S]_0$ (mM)\",size=fontsize)\n",
    "ax[0].tick_params(axis='both',labelsize=fontsize)\n",
    "for i in range(n_trials):\n",
    "    ax[0].plot(s0,data[:,i],'o')\n",
    "ax[0].plot(s0,truth,'-',lw=2,label=\"Truth\")\n",
    "ax[1].grid(which='major', axis='both', color='#808080', linestyle='--')\n",
    "ax[1].set_ylabel(\"$1/v_0$ (s/$\\mu$M)\",size=fontsize)\n",
    "ax[1].set_xlabel(\"$1/[S]_0$ (1/mM)\",size=fontsize)\n",
    "ax[1].tick_params(axis='both',labelsize=fontsize)\n",
    "for i in range(n_trials):\n",
    "    ax[1].plot(1/s0,1/data[:,i],'o')\n",
    "ax[1].plot(1/s0,1/truth,'-',lw=2,label=\"Truth\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a472c",
   "metadata": {},
   "source": [
    "Non-linear fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c71ec5a2",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_max =  7.6 +/- 0.1 muM/s\n",
      "Km =  4.2 +/- 0.1 mM\n"
     ]
    }
   ],
   "source": [
    "# perform non-linear fit\n",
    "# import least squares function from scipy library\n",
    "from scipy.optimize import curve_fit\n",
    "# define Michaelis-Menten function\n",
    "def mm(s,vmax,Km):  \n",
    "    return vmax*s/(Km + s)\n",
    "# make an initial guess of parameters\n",
    "x0 = np.array([1.0,1.0])\n",
    "popt, pcov = curve_fit(mm, s0_total.flatten(), data.flatten())\n",
    "err = np.sqrt(np.diag(pcov))\n",
    "print(\"v_max = \", np.round(popt[0],1),\"+/-\", np.round(err[0],1), \"muM/s\")\n",
    "print(\"Km = \", np.round(popt[1],1),\"+/-\", np.round(err[1],1), \"mM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e1ea0",
   "metadata": {},
   "source": [
    "Linear-fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b505f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_max =  7.8 +/- 0.7 muM/s\n",
      "Km =  4.4 +/- 0.5 mM\n"
     ]
    }
   ],
   "source": [
    "# perform linear fit\n",
    "# import least squares function from scipy library\n",
    "from scipy.optimize import curve_fit\n",
    "# define Michaelis-Menten function\n",
    "def mm_lineweaver_burke(s,m,b):  \n",
    "    return m*s + b\n",
    "# make an initial guess of parameters\n",
    "popt_lwb, pcov = curve_fit(mm_lineweaver_burke, 1/s0_total.flatten(), 1/data.flatten())\n",
    "err_lwb = np.sqrt(np.diag(pcov))\n",
    "vmax_lwb = 1/popt_lwb[1]\n",
    "vmax_lwb_err = vmax_lwb*err_lwb[1]/popt_lwb[1]\n",
    "Km_lwb = popt_lwb[0]/popt_lwb[1]\n",
    "Km_lwb_err = Km_lwb*np.sqrt( (err_lwb[0]/popt_lwb[0])**2 + (err_lwb[1]/popt_lwb[1])**2)\n",
    "print(\"v_max = \", np.round(vmax_lwb,1),\"+/-\", np.round(vmax_lwb_err,1), \"muM/s\")\n",
    "print(\"Km = \", np.round(Km_lwb,1),\"+/-\", np.round(Km_lwb_err,1), \"mM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141bb8d",
   "metadata": {},
   "source": [
    "In this case, we see that the non-linear fit produces values closer to the true values as compared the the Lineweaver-Burk linearization.  This is why it is suggested to use non-linear fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94320ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}